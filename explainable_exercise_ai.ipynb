{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise: Explaining an AI Model used for explaining similarity between Explainable AI exercises\n",
    "\n",
    "\n",
    "**Student:** Markus Vogl<br>\n",
    "**Matr. Nr:** k1155575<br>\n",
    "**Course:** Explainable AI<br>\n",
    "\n",
    "![](https://i.imgflip.com/4tyf70.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data: Exercise data\n",
    "The submitted ipython notebooks of this course are used.\n",
    "\n",
    "* **Fetching:** All projects are pulled in parallel via the system git that requires the correct credentials on your system in your ~/.gitconfig directory.\n",
    "\n",
    "* **Filtering:** I use jupyter-nbconvert to extract the source code from ipython files (the typical hand-in-format) from the root of the project.\n",
    "\n",
    "* **Preprocessing:** As the model is limited to 512 tokens (not signs, source code is tokenzied), I strip all comments, emtpy newlines and outputs via regex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fun fact: Data sizes\n",
    "\n",
    "![](https://s12.directupload.net/images/210115/6v57kc5w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model: CodeBERT\n",
    "The used model is Microsofts [codeBERT](https://github.com/microsoft/CodeBERT), a variation of **RoBERTa** pre-trained on programming languages. It's based on the huggingface transformers libary which itself is based on pytorch.\n",
    "\n",
    "The sequences have to be trimmed to a length of 512, as [this has been proven to be easy and effective](https://stackoverflow.com/questions/58636587/how-to-use-bert-for-long-text-classification). Even though there exist other approaches that work better for some scenarios.\n",
    "\n",
    "* BERT is currently the state of the art for text encoding / embedding\n",
    "* Pretrained on normal human text -> CodeBert\n",
    "* I chose CodeBert over CuBERT, because Microsoft seems to be a better source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Explainability model: Embedding Projector\n",
    "The explainability model is the paper [Embedding Projector: Interactive Visualization and Interpretation of Embeddings](https://arxiv.org/abs/1611.05469) by Smilkov, et al. from 2016.\n",
    "\n",
    "![](https://raw.githubusercontent.com/justindujardin/projector/ab50806029db3f7dea9d3064ce5ac7cb64fc7753/oss_data/spaCy_attn_learned_query_vector_preview.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Explainability framework: Hohman et al\n",
    "Short exploration of the big questions posed in the format [Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers](https://arxiv.org/abs/1801.06889) by Hohman et. al from 2018.\n",
    "\n",
    "![](https://fredhohman.com/visual-analytics-in-deep-learning/images/deepvis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why, Who, What, When, Where, How\n",
    "According to Hohnman et. al the *Embedding Projector* paper already covers:\n",
    "\n",
    "Question | Criterion | Explanation\n",
    "--- | --- | ---\n",
    "Why | Interpretability & Explainability | You can interpret and explain embeddings of any kind\n",
    "Who | Model Users | Data Scientists\n",
    "What | Individual Computational Units | The tool can downproject with PCA and TSNE\n",
    "What | Neurons in High-dimensional Space | Embeddings\n",
    "What | Aggregated Information | You can aggregate multiple embeddings and compare them\n",
    "When | After Training |\n",
    "Where | NIPS Conference |\n",
    "How | Dimensionality Reduction & Scatter Plots | PCA and TSN-E\n",
    "How | Instance-based Analysis & Exploration | Exploring similiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contributions\n",
    "\n",
    "In addition to the stated factors, this adds the explainability approaches:\n",
    "\n",
    "Question | Criterion | Explanation\n",
    "--- | --- | ---\n",
    "Why | Comparing & Selecting Models | This allows you to plug in other encoders like LSTMs, other BERT's etc. to compare them easily\n",
    "Why | Education | It's an easy showcase of git, BERT embedding-extraction, visualization\n",
    "Why | Education | It's meant to compare student exercises and find plagiarism\n",
    "Who | Model Developers & Builders | as the students in this course can compare their approach to the other teams\n",
    "Who | Model users | Teachers of any github classroom can just plug in their data and start\n",
    "Who | Non-experts | can just plug in their github classroom data, run it and get cool visualizations (given they manage the setup)\n",
    "Where | - | JKU Linz, XAI Course\n",
    "How | Interactive Experimentation | You can change parameters like stripping newlines/comments and see how that effects your embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "classroom = \"jku-icg-classroom\"\n",
    "prefix = \"xai_proj_space_2020\"\n",
    "teams = ['xai',\n",
    " 'xai-wyoming',\n",
    " 'backpropagatedstudents',\n",
    " 'aikraken',\n",
    " 'mysterious-potatoes',\n",
    " 'the-explainables',\n",
    " 'aiexplained',\n",
    " 'group0',\n",
    " 'xai-explainable-black-magic',\n",
    " 'viennxai',\n",
    " 'xai_group_a',\n",
    " 'hands-on-xai',\n",
    " 'xai-random-group',\n",
    " 'feel_free_2_join',\n",
    " 'forum_feel_free_to_join',\n",
    " 'explain_it_explainable',\n",
    " 'yet-another-group',\n",
    " 'explanation-is-all-you-need',\n",
    " 'let_me_explain_you',\n",
    " 'dirty-mike-and-the-gang',\n",
    " 'explain-the-unexplainable',\n",
    " 'nothin_but_a_peanut',\n",
    " '3_and_1-2_ger']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fetching from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re, os, itertools, pandas\n",
    "from multiprocessing import Pool\n",
    "# also requires the system utilities git, rm and jupyter-nbconvert\n",
    "EXT = \"ipynb\"\n",
    "COLUMNS = [\"filename\", \"team\", \"exercise\", \"url\"]\n",
    "\n",
    "# Fetch contents of ipynb files\n",
    "def fetch(team, strip_comments=True, strip_empty_lines=True):\n",
    "    path = f\"{classroom}/{prefix}/{team}\"\n",
    "    cp = f\"{classroom}/{prefix}\"\n",
    "    if not os.path.exists(path):\n",
    "        os.system(f\"git clone git@github.com:{cp}-{team}.git {path}\")\n",
    "    print(\"⬇️\", end=\"\")\n",
    "    file_content = {}\n",
    "    files = filter(lambda n: n.endswith(EXT), os.listdir(path))\n",
    "    for notebook in files:\n",
    "        full_url = f\"https://github.com/{cp}-{team}/{notebook}\"\n",
    "        cmd = f\"jupyter-nbconvert {path}/{notebook} --to python --stdout\"\n",
    "        fc = os.popen(cmd).read()\n",
    "        if strip_comments:    fc = re.sub(\"#.+\", \"\", fc)\n",
    "        if strip_empty_lines: fc = re.sub(\"\\n+\", \"\\n\", fc)\n",
    "        no_ext = (notebook.replace('.'+EXT, '')\n",
    "        file_content[no_ext, team, prefix, full_url)] = fc\n",
    "    print(\"✅\", end=\"\")\n",
    "    return file_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multithreading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅\n",
      "⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️✅⬇️⬇️⬇️⬇️⬇️⬇️✅✅⬇️⬇️⬇️⬇️⬇️⬇️⬇️✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>team</th>\n",
       "      <th>exercise</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>solution</td>\n",
       "      <td>xai</td>\n",
       "      <td>xai_proj_space_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_proj_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solution</td>\n",
       "      <td>xai-wyoming</td>\n",
       "      <td>xai_proj_space_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_proj_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>solution</td>\n",
       "      <td>backpropagatedstudents</td>\n",
       "      <td>xai_proj_space_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_proj_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solution</td>\n",
       "      <td>aikraken</td>\n",
       "      <td>xai_proj_space_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_proj_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>solution</td>\n",
       "      <td>mysterious-potatoes</td>\n",
       "      <td>xai_proj_space_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_proj_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6 - LIME_explanations_run</td>\n",
       "      <td>nothin_but_a_peanut</td>\n",
       "      <td>xai_model_explanation_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Untitled</td>\n",
       "      <td>nothin_but_a_peanut</td>\n",
       "      <td>xai_model_explanation_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>imagenet labels to pkl file</td>\n",
       "      <td>nothin_but_a_peanut</td>\n",
       "      <td>xai_model_explanation_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2 - Visualization of Fully Connected Layer Neu...</td>\n",
       "      <td>nothin_but_a_peanut</td>\n",
       "      <td>xai_model_explanation_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>solution</td>\n",
       "      <td>3_and_1-2_ger</td>\n",
       "      <td>xai_model_explanation_2020</td>\n",
       "      <td>https://github.com/jku-icg-classroom/xai_model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename                    team  \\\n",
       "0                                            solution                     xai   \n",
       "1                                            solution             xai-wyoming   \n",
       "2                                            solution  backpropagatedstudents   \n",
       "3                                            solution                aikraken   \n",
       "4                                            solution     mysterious-potatoes   \n",
       "..                                                ...                     ...   \n",
       "73                          6 - LIME_explanations_run     nothin_but_a_peanut   \n",
       "74                                           Untitled     nothin_but_a_peanut   \n",
       "75                        imagenet labels to pkl file     nothin_but_a_peanut   \n",
       "76  2 - Visualization of Fully Connected Layer Neu...     nothin_but_a_peanut   \n",
       "77                                           solution           3_and_1-2_ger   \n",
       "\n",
       "                      exercise  \\\n",
       "0          xai_proj_space_2020   \n",
       "1          xai_proj_space_2020   \n",
       "2          xai_proj_space_2020   \n",
       "3          xai_proj_space_2020   \n",
       "4          xai_proj_space_2020   \n",
       "..                         ...   \n",
       "73  xai_model_explanation_2020   \n",
       "74  xai_model_explanation_2020   \n",
       "75  xai_model_explanation_2020   \n",
       "76  xai_model_explanation_2020   \n",
       "77  xai_model_explanation_2020   \n",
       "\n",
       "                                                  url  \n",
       "0   https://github.com/jku-icg-classroom/xai_proj_...  \n",
       "1   https://github.com/jku-icg-classroom/xai_proj_...  \n",
       "2   https://github.com/jku-icg-classroom/xai_proj_...  \n",
       "3   https://github.com/jku-icg-classroom/xai_proj_...  \n",
       "4   https://github.com/jku-icg-classroom/xai_proj_...  \n",
       "..                                                ...  \n",
       "73  https://github.com/jku-icg-classroom/xai_model...  \n",
       "74  https://github.com/jku-icg-classroom/xai_model...  \n",
       "75  https://github.com/jku-icg-classroom/xai_model...  \n",
       "76  https://github.com/jku-icg-classroom/xai_model...  \n",
       "77  https://github.com/jku-icg-classroom/xai_model...  \n",
       "\n",
       "[78 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_multithreaded():\n",
    "    pool = Pool(len(teams))\n",
    "    dicts = pool.map(fetch, teams)\n",
    "    items = [fc.items() for fc in dicts]\n",
    "    items_flat = itertools.chain(*items)\n",
    "    return dict(items_flat)\n",
    "\n",
    "file_content = fetch_multithreaded(); print()\n",
    "prefix = \"xai_model_explanation_2020\"\n",
    "file_content.update(fetch_multithreaded())\n",
    "pandas.DataFrame(file_content.keys(), columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Embedding extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "model.eval()  # speeds up stuff\n",
    "\n",
    "def embed(file_content, tokenizer, model, max_length=512):\n",
    "    content_list = list(file_content.values())\n",
    "    # as pytorch, with padding, truncated to exactly 512 length\n",
    "    tokens = tokenizer(content_list, return_tensors=\"pt\", padding=True, \n",
    "                       max_length=max_length, truncation=True)\n",
    "    # Return dict of {filename : numpy bert token}\n",
    "    return model(**tokens)[\"pooler_output\"].detach().numpy()\n",
    "\n",
    "embedding = embed(file_content, tokenizer, model)\n",
    "\n",
    "# save files for visualizer\n",
    "np.savetxt(classroom+\"-embedding.tsv\", embedding, delimiter=\"\\t\")\n",
    "names = [\"\\t\".join(fc) for fc in file_content]\n",
    "hdr = \"filename\\tteam\\tproject\\tfull_url\"\n",
    "np.savetxt(classroom+\"-names.tsv\", names, fmt=\"%s\", header=\"\\t\".join(COLUMNS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizer\n",
    "Standalone instances:\n",
    "* https://projector.tensorflow.org/\n",
    "* https://justindujardin.github.io/projector/ (Works better for me for some reason)\n",
    "\n",
    "Code:\n",
    "* https://github.com/justindujardin/projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualization: Code similarity betwen projects\n",
    "\n",
    "![](https://s12.directupload.net/images/210115/qisi9nmh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualization: Code similarity between teams\n",
    "\n",
    "Example: Two teams left in the given example - distance 0.0 as it's the same file.\n",
    "\n",
    "![](https://s12.directupload.net/images/210115/qlj38o6e.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}